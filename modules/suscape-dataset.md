---
layout: page
title: SUScape数据集介绍
---

# SUScape数据集介绍

> 🎯 **模块目标**：了解SUScape数据集的结构、特点和应用场景

### 📊 数据集概述


[SUScape自动驾驶数据集](https://www.suscape.net) 
是一个大规模自动驾驶数据集。该数据集包含丰富的传感器信息和完整的3D对象标注。我们从超过50小时的驾驶记录中精选了深圳的1059个交通场景，涵盖不同道路类型、光照条件及天气情况。

- 1059个每个20秒的场景
- 42.3K次激光雷达扫描
- 254K张RGB相机图像
- 254K张红外相机图像
- 2Hz的人工标注
- 1.26M个带追踪ID的3D边界框
- 60K个对象跟踪轨迹
- 36个对象类别
- 包含雨伞、乘客、车门开启等属性
- 自车位姿/激光雷达位姿

### 硬件平台

![Car Image](./suscape-dataset-images/car.png)

| 组件                 | 数量|描述                                             |
|----------------------|--|------------------------------------------------|
| 128线束激光雷达      | 1 |单个高精度激光雷达，用于获取环境深度信息              |
| 32线激光雷达         | 4|布置于车辆四周，覆盖盲区，实现360°检测           |
| 毫米波雷达           | 6|用于监测车辆周边的动态物体                         |
| 高清相机             | 6|360°无死角捕捉环境图像                                 |
| 红外相机             | 6|用于低光环境下的图像采集                               |
| GPS/IMU              | 1|用于提供精确定位和运动姿态数据                         |
| 时钟同步服务器       | 1|保证多传感器数据高精度时钟同步                           |
| 车载工业计算机       | 1|高性能数据处理平台，支持传感器数据的实时整合和处理         |


### 时间/空间同步


自动驾驶系统中，多传感器协同工作是实现高精度感知与决策的关键。对传感器进行时间同步，可以确保不同设备在同一时刻获取的数据具有一致性，避免因时间延迟而导致数据错位；而空间同步则通过校准各传感器在车辆上的安装位置和朝向，实现数据在统一坐标系下的精准对齐，便于多模态数据融合和综合分析，从而增强场景理解和环境感知的准确性。


![gps/rtk](./suscape-dataset-images/rtk.png)


![closk sync](./suscape-dataset-images/clock-sync.png)



![lidar-camera-trigger](./suscape-dataset-images/lidar-cam-trigger.png)




#### 相机内参标定

相机标定是指通过采集一系列标准几何图案的图像（如棋盘格或圆点阵列），来确定相机的内部参数（焦距、主点、镜头畸变等）。这种标定可以提高图像测量和三维重建的准确性，并为后续的视觉处理、目标检测、定位与追踪等任务提供关键数据支持。

标定工具参考 https://wiki.ros.org/camera_calibration

![camera-calibration](./suscape-dataset-images/cam-calib.png)


红外相机标定除了几何特性标定外，还有温度的标定，下图显示的是几何特性的标定方法，温度标定我们采用厂家数据。
红外相机标定时需要待标定物和背景有明显的温差，才能检测到几何图案轮廓。我们采用有孔的标定板，选取天空作为背景。
![camera-calibration](./suscape-dataset-images/infrared-cam-calib.png)



外参标定


![camera-calibration](./suscape-dataset-images/radar-lidar-calib.png)

### 数据采集

数据采集平台基于比亚迪轿车改造而成，配置有１个128线束激光雷达，４个32线盲区覆盖激光雷达，６个毫米波雷达，360度覆盖的高清相机和红外相机，GPS/IMU，以及司机面部监控相机和心跳监控传感器，同时配有高精度时钟同步服务器及高性能车载工业计算机，全车支持线控，已完成传感器标定，数据采集及监控软件的开发，以具备数据采集和自动驾驶测试条件．基于该平台，目前正在进行数据集的采集和处理工作．

### 数据筛选


数据集按场景组织，每个场景时长20秒。根据天气/光照情况/路况/复杂情况等综合考虑选取待标注场景。

### 数据标注

数据集标注方面，本项目开发的3D标注平台，可以支持点云/图像等多模态数据的可视化功能和方便高效的标注检查及编辑功能，支持３D目标检测及目标追踪数据集的标注．在标注效率方面，本项目开发了基于启发式的和基于深度学习的辅助标注算法，与其他同类别标注工具相比，可以极大的提高标注效率．除此之外，本项目也在进行其他自动标注算法的研究，包括基于场景流的目标检测，基于3D/2D融合的跨域学习方法的目标检测，以及多目标联合检测与追踪算法等．


## 🔗 导航链接

- [返回主页](../index.html)
- [下一模块：POINTS工具介绍](points-tool.html)
- [数据分析模块](data-analysis.html)
