---
layout: page
title: æ•°æ®æ ‡æ³¨
---

# æ•°æ®æ ‡æ³¨

> ğŸ·ï¸ **æ¨¡å—ç›®æ ‡**ï¼šæŒæ¡æ•°æ®æ ‡æ³¨æŠ€æœ¯ï¼Œæ„å»ºé«˜è´¨é‡è®­ç»ƒæ•°æ®é›†

## ğŸ“– æ•°æ®æ ‡æ³¨æ¦‚è¿°

æ•°æ®æ ‡æ³¨æ˜¯æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é¡¹ç›®çš„åŸºç¡€å·¥ä½œï¼Œæ¶‰åŠä¸ºåŸå§‹æ•°æ®æ·»åŠ æ ‡ç­¾ã€æ³¨é‡Šæˆ–å…ƒæ•°æ®ï¼Œä»¥ä¾¿ç®—æ³•èƒ½å¤Ÿå­¦ä¹ å’Œè¯†åˆ«æ¨¡å¼ã€‚é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®æ˜¯æ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ ã€‚

## ğŸ¯ æ ‡æ³¨ç±»å‹ä¸åº”ç”¨

### å›¾åƒæ ‡æ³¨
- **åˆ†ç±»æ ‡æ³¨**ï¼šä¸ºå›¾åƒåˆ†é…ç±»åˆ«æ ‡ç­¾
- **ç›®æ ‡æ£€æµ‹**ï¼šæ ‡æ³¨ç‰©ä½“è¾¹ç•Œæ¡†å’Œç±»åˆ«
- **è¯­ä¹‰åˆ†å‰²**ï¼šåƒç´ çº§åˆ«çš„ç±»åˆ«æ ‡æ³¨
- **å®ä¾‹åˆ†å‰²**ï¼šåŒºåˆ†åŒç±»åˆ«çš„ä¸åŒå®ä¾‹
- **å…³é”®ç‚¹æ£€æµ‹**ï¼šæ ‡æ³¨äººä½“å§¿æ€ã€é¢éƒ¨ç‰¹å¾ç‚¹

### æ–‡æœ¬æ ‡æ³¨
- **æƒ…æ„Ÿåˆ†æ**ï¼šæ ‡æ³¨æ–‡æœ¬æƒ…æ„Ÿå€¾å‘
- **å‘½åå®ä½“è¯†åˆ«**ï¼šæ ‡æ³¨äººåã€åœ°åã€æœºæ„å
- **å…³ç³»æŠ½å–**ï¼šæ ‡æ³¨å®ä½“é—´çš„å…³ç³»
- **æ–‡æœ¬åˆ†ç±»**ï¼šä¸ºæ–‡æ¡£åˆ†é…ä¸»é¢˜æ ‡ç­¾
- **æœºå™¨ç¿»è¯‘**ï¼šæä¾›ç¿»è¯‘å¯¹ç…§

### éŸ³é¢‘æ ‡æ³¨
- **è¯­éŸ³è¯†åˆ«**ï¼šæ ‡æ³¨è¯­éŸ³å†…å®¹
- **éŸ³ä¹åˆ†ç±»**ï¼šæ ‡æ³¨éŸ³ä¹é£æ ¼ã€æƒ…ç»ª
- **ç¯å¢ƒå£°éŸ³**ï¼šæ ‡æ³¨å£°éŸ³äº‹ä»¶å’Œåœºæ™¯
- **è¯´è¯äººè¯†åˆ«**ï¼šæ ‡æ³¨è¯´è¯äººèº«ä»½

### è§†é¢‘æ ‡æ³¨
- **åŠ¨ä½œè¯†åˆ«**ï¼šæ ‡æ³¨è§†é¢‘ä¸­çš„è¡Œä¸ºåŠ¨ä½œ
- **åœºæ™¯åˆ†å‰²**ï¼šæ ‡æ³¨è§†é¢‘åœºæ™¯è¾¹ç•Œ
- **ç›®æ ‡è·Ÿè¸ª**ï¼šæ ‡æ³¨ç›®æ ‡åœ¨è§†é¢‘ä¸­çš„è½¨è¿¹
- **äº‹ä»¶æ£€æµ‹**ï¼šæ ‡æ³¨ç‰¹å®šäº‹ä»¶çš„æ—¶é—´ç‚¹

## ğŸ› ï¸ æ ‡æ³¨å·¥å…·ä¸å¹³å°

### å¼€æºæ ‡æ³¨å·¥å…·

#### å›¾åƒæ ‡æ³¨å·¥å…·
```python
# LabelImg - ç›®æ ‡æ£€æµ‹æ ‡æ³¨
# å®‰è£…ï¼špip install labelImg
# ä½¿ç”¨ï¼šlabelImg

# åŸºäºPythonçš„è‡ªå®šä¹‰æ ‡æ³¨å·¥å…·
import tkinter as tk
from tkinter import filedialog, messagebox
from PIL import Image, ImageTk
import json
import os

class ImageAnnotationTool:
    def __init__(self, root):
        self.root = root
        self.root.title("å›¾åƒæ ‡æ³¨å·¥å…·")
        self.root.geometry("1200x800")
        
        self.image_path = ""
        self.annotations = []
        self.current_bbox = None
        self.start_x = 0
        self.start_y = 0
        
        self.setup_ui()
    
    def setup_ui(self):
        # èœå•æ 
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="æ–‡ä»¶", menu=file_menu)
        file_menu.add_command(label="æ‰“å¼€å›¾åƒ", command=self.load_image)
        file_menu.add_command(label="ä¿å­˜æ ‡æ³¨", command=self.save_annotations)
        file_menu.add_command(label="åŠ è½½æ ‡æ³¨", command=self.load_annotations)
        
        # ä¸»æ¡†æ¶
        main_frame = tk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # å·¦ä¾§ï¼šå›¾åƒæ˜¾ç¤º
        self.image_frame = tk.Frame(main_frame, bg="white")
        self.image_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        self.canvas = tk.Canvas(self.image_frame, bg="white")
        self.canvas.pack(fill=tk.BOTH, expand=True)
        
        # ç»‘å®šé¼ æ ‡äº‹ä»¶
        self.canvas.bind("<Button-1>", self.start_bbox)
        self.canvas.bind("<B1-Motion>", self.draw_bbox)
        self.canvas.bind("<ButtonRelease-1>", self.end_bbox)
        
        # å³ä¾§ï¼šæ§åˆ¶é¢æ¿
        control_frame = tk.Frame(main_frame, width=300)
        control_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=(10, 0))
        control_frame.pack_propagate(False)
        
        # ç±»åˆ«é€‰æ‹©
        tk.Label(control_frame, text="é€‰æ‹©ç±»åˆ«:", font=("Arial", 12)).pack(pady=5)
        self.class_var = tk.StringVar(value="person")
        self.class_entry = tk.Entry(control_frame, textvariable=self.class_var)
        self.class_entry.pack(pady=5, fill=tk.X)
        
        # é¢„å®šä¹‰ç±»åˆ«
        classes = ["person", "car", "bike", "dog", "cat"]
        for cls in classes:
            btn = tk.Button(control_frame, text=cls, 
                          command=lambda c=cls: self.class_var.set(c))
            btn.pack(pady=2, fill=tk.X)
        
        # æ ‡æ³¨åˆ—è¡¨
        tk.Label(control_frame, text="æ ‡æ³¨åˆ—è¡¨:", font=("Arial", 12)).pack(pady=(20, 5))
        
        self.annotation_listbox = tk.Listbox(control_frame, height=10)
        self.annotation_listbox.pack(fill=tk.BOTH, expand=True, pady=5)
        
        # åˆ é™¤æŒ‰é’®
        tk.Button(control_frame, text="åˆ é™¤é€‰ä¸­æ ‡æ³¨", 
                 command=self.delete_annotation).pack(pady=5, fill=tk.X)
        
        # æ¸…ç©ºæŒ‰é’®
        tk.Button(control_frame, text="æ¸…ç©ºæ‰€æœ‰æ ‡æ³¨", 
                 command=self.clear_annotations).pack(pady=5, fill=tk.X)
    
    def load_image(self):
        file_path = filedialog.askopenfilename(
            filetypes=[("Image files", "*.jpg *.jpeg *.png *.bmp *.gif")]
        )
        if file_path:
            self.image_path = file_path
            self.display_image()
    
    def display_image(self):
        if self.image_path:
            image = Image.open(self.image_path)
            # è°ƒæ•´å›¾åƒå¤§å°ä»¥é€‚åº”ç”»å¸ƒ
            canvas_width = self.canvas.winfo_width()
            canvas_height = self.canvas.winfo_height()
            
            if canvas_width > 1 and canvas_height > 1:
                image.thumbnail((canvas_width, canvas_height), Image.Resampling.LANCZOS)
                self.photo = ImageTk.PhotoImage(image)
                self.canvas.delete("all")
                self.canvas.create_image(0, 0, anchor=tk.NW, image=self.photo)
                self.canvas.config(scrollregion=self.canvas.bbox("all"))
    
    def start_bbox(self, event):
        self.start_x = self.canvas.canvasx(event.x)
        self.start_y = self.canvas.canvasy(event.y)
        
        if self.current_bbox:
            self.canvas.delete(self.current_bbox)
        
        self.current_bbox = self.canvas.create_rectangle(
            self.start_x, self.start_y, self.start_x, self.start_y,
            outline="red", width=2
        )
    
    def draw_bbox(self, event):
        cur_x = self.canvas.canvasx(event.x)
        cur_y = self.canvas.canvasy(event.y)
        
        self.canvas.coords(self.current_bbox, self.start_x, self.start_y, cur_x, cur_y)
    
    def end_bbox(self, event):
        end_x = self.canvas.canvasx(event.x)
        end_y = self.canvas.canvasy(event.y)
        
        # ç¡®ä¿è¾¹ç•Œæ¡†æœ‰æ•ˆ
        if abs(end_x - self.start_x) > 5 and abs(end_y - self.start_y) > 5:
            annotation = {
                "class": self.class_var.get(),
                "bbox": [
                    min(self.start_x, end_x),
                    min(self.start_y, end_y),
                    max(self.start_x, end_x),
                    max(self.start_y, end_y)
                ]
            }
            self.annotations.append(annotation)
            self.update_annotation_list()
        else:
            self.canvas.delete(self.current_bbox)
        
        self.current_bbox = None
    
    def update_annotation_list(self):
        self.annotation_listbox.delete(0, tk.END)
        for i, ann in enumerate(self.annotations):
            self.annotation_listbox.insert(tk.END, 
                f"{i+1}. {ann['class']}: {ann['bbox']}")
    
    def delete_annotation(self):
        selection = self.annotation_listbox.curselection()
        if selection:
            index = selection[0]
            del self.annotations[index]
            self.update_annotation_list()
            self.redraw_annotations()
    
    def clear_annotations(self):
        self.annotations = []
        self.update_annotation_list()
        self.canvas.delete("bbox")
    
    def redraw_annotations(self):
        self.canvas.delete("bbox")
        for ann in self.annotations:
            bbox = ann["bbox"]
            self.canvas.create_rectangle(
                bbox[0], bbox[1], bbox[2], bbox[3],
                outline="red", width=2, tags="bbox"
            )
    
    def save_annotations(self):
        if not self.image_path:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½å›¾åƒ")
            return
        
        annotation_file = self.image_path.rsplit('.', 1)[0] + '.json'
        annotation_data = {
            "image_path": self.image_path,
            "annotations": self.annotations
        }
        
        with open(annotation_file, 'w', encoding='utf-8') as f:
            json.dump(annotation_data, f, indent=2, ensure_ascii=False)
        
        messagebox.showinfo("æˆåŠŸ", f"æ ‡æ³¨å·²ä¿å­˜è‡³ {annotation_file}")
    
    def load_annotations(self):
        if not self.image_path:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½å›¾åƒ")
            return
        
        annotation_file = self.image_path.rsplit('.', 1)[0] + '.json'
        if os.path.exists(annotation_file):
            with open(annotation_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.annotations = data.get("annotations", [])
                self.update_annotation_list()
                self.redraw_annotations()
        else:
            messagebox.showinfo("ä¿¡æ¯", "æœªæ‰¾åˆ°å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶")

# å¯åŠ¨æ ‡æ³¨å·¥å…·
if __name__ == "__main__":
    root = tk.Tk()
    app = ImageAnnotationTool(root)
    root.mainloop()
```

#### æ–‡æœ¬æ ‡æ³¨å·¥å…·
```python
import streamlit as st
import pandas as pd
import json
from datetime import datetime

class TextAnnotationTool:
    def __init__(self):
        self.init_session_state()
    
    def init_session_state(self):
        if 'texts' not in st.session_state:
            st.session_state.texts = []
        if 'annotations' not in st.session_state:
            st.session_state.annotations = {}
        if 'current_index' not in st.session_state:
            st.session_state.current_index = 0
    
    def load_texts(self, file):
        """åŠ è½½å¾…æ ‡æ³¨æ–‡æœ¬"""
        if file.type == "text/csv":
            df = pd.read_csv(file)
            if 'text' in df.columns:
                st.session_state.texts = df['text'].tolist()
            else:
                st.error("CSVæ–‡ä»¶å¿…é¡»åŒ…å«'text'åˆ—")
        elif file.type == "application/json":
            data = json.load(file)
            if isinstance(data, list):
                st.session_state.texts = data
            else:
                st.error("JSONæ–‡ä»¶å¿…é¡»æ˜¯æ–‡æœ¬åˆ—è¡¨")
        else:
            # çº¯æ–‡æœ¬æ–‡ä»¶
            content = str(file.read(), "utf-8")
            st.session_state.texts = content.split('\n')
        
        st.session_state.current_index = 0
        st.success(f"æˆåŠŸåŠ è½½ {len(st.session_state.texts)} æ¡æ–‡æœ¬")
    
    def annotate_sentiment(self):
        """æƒ…æ„Ÿåˆ†ææ ‡æ³¨"""
        if not st.session_state.texts:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡æœ¬æ–‡ä»¶")
            return
        
        st.subheader("æƒ…æ„Ÿåˆ†ææ ‡æ³¨")
        
        # æ˜¾ç¤ºå½“å‰æ–‡æœ¬
        current_text = st.session_state.texts[st.session_state.current_index]
        st.text_area("å½“å‰æ–‡æœ¬", current_text, height=100, disabled=True)
        
        # æ ‡æ³¨é€‰é¡¹
        sentiment = st.radio(
            "é€‰æ‹©æƒ…æ„Ÿæ ‡ç­¾",
            ["ç§¯æ", "æ¶ˆæ", "ä¸­æ€§"],
            key=f"sentiment_{st.session_state.current_index}"
        )
        
        # ç½®ä¿¡åº¦
        confidence = st.slider("æ ‡æ³¨ç½®ä¿¡åº¦", 0.0, 1.0, 0.8, 0.1)
        
        # ä¿å­˜æ ‡æ³¨
        if st.button("ä¿å­˜æ ‡æ³¨"):
            text_id = st.session_state.current_index
            st.session_state.annotations[text_id] = {
                "text": current_text,
                "sentiment": sentiment,
                "confidence": confidence,
                "timestamp": datetime.now().isoformat()
            }
            st.success("æ ‡æ³¨å·²ä¿å­˜")
            
            # è‡ªåŠ¨è·³è½¬åˆ°ä¸‹ä¸€æ¡
            if st.session_state.current_index < len(st.session_state.texts) - 1:
                st.session_state.current_index += 1
                st.experimental_rerun()
    
    def annotate_ner(self):
        """å‘½åå®ä½“è¯†åˆ«æ ‡æ³¨"""
        if not st.session_state.texts:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡æœ¬æ–‡ä»¶")
            return
        
        st.subheader("å‘½åå®ä½“è¯†åˆ«æ ‡æ³¨")
        
        current_text = st.session_state.texts[st.session_state.current_index]
        st.text_area("å½“å‰æ–‡æœ¬", current_text, height=100, disabled=True)
        
        # å®ä½“ç±»å‹
        entity_types = ["PERSON", "ORG", "GPE", "MONEY", "DATE", "TIME"]
        
        # å®ä½“æ ‡æ³¨
        entities = []
        
        st.write("æ ‡æ³¨å®ä½“ï¼š")
        for i in range(5):  # æœ€å¤šæ ‡æ³¨5ä¸ªå®ä½“
            col1, col2, col3, col4 = st.columns([2, 2, 1, 1])
            
            with col1:
                entity_text = st.text_input(f"å®ä½“æ–‡æœ¬ {i+1}", key=f"entity_text_{i}")
            
            with col2:
                entity_type = st.selectbox(f"å®ä½“ç±»å‹ {i+1}", 
                                         [""] + entity_types, key=f"entity_type_{i}")
            
            with col3:
                start_pos = st.number_input(f"å¼€å§‹ä½ç½® {i+1}", 
                                          min_value=0, key=f"start_{i}")
            
            with col4:
                end_pos = st.number_input(f"ç»“æŸä½ç½® {i+1}", 
                                        min_value=0, key=f"end_{i}")
            
            if entity_text and entity_type:
                entities.append({
                    "text": entity_text,
                    "type": entity_type,
                    "start": int(start_pos),
                    "end": int(end_pos)
                })
        
        # ä¿å­˜æ ‡æ³¨
        if st.button("ä¿å­˜NERæ ‡æ³¨"):
            text_id = st.session_state.current_index
            st.session_state.annotations[text_id] = {
                "text": current_text,
                "entities": entities,
                "timestamp": datetime.now().isoformat()
            }
            st.success("NERæ ‡æ³¨å·²ä¿å­˜")
    
    def navigation(self):
        """å¯¼èˆªæ§åˆ¶"""
        if st.session_state.texts:
            col1, col2, col3 = st.columns([1, 2, 1])
            
            with col1:
                if st.button("ä¸Šä¸€æ¡"):
                    if st.session_state.current_index > 0:
                        st.session_state.current_index -= 1
                        st.experimental_rerun()
            
            with col2:
                st.write(f"å½“å‰è¿›åº¦: {st.session_state.current_index + 1} / {len(st.session_state.texts)}")
            
            with col3:
                if st.button("ä¸‹ä¸€æ¡"):
                    if st.session_state.current_index < len(st.session_state.texts) - 1:
                        st.session_state.current_index += 1
                        st.experimental_rerun()
    
    def export_annotations(self):
        """å¯¼å‡ºæ ‡æ³¨ç»“æœ"""
        if st.session_state.annotations:
            annotations_json = json.dumps(st.session_state.annotations, 
                                        indent=2, ensure_ascii=False)
            
            st.download_button(
                label="ä¸‹è½½æ ‡æ³¨ç»“æœ",
                data=annotations_json,
                file_name=f"annotations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        st.title("æ–‡æœ¬æ ‡æ³¨å·¥å…·")
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶",
            type=['txt', 'csv', 'json'],
            help="æ”¯æŒtxtã€csvã€jsonæ ¼å¼"
        )
        
        if uploaded_file:
            self.load_texts(uploaded_file)
        
        # æ ‡æ³¨ç±»å‹é€‰æ‹©
        annotation_type = st.sidebar.selectbox(
            "é€‰æ‹©æ ‡æ³¨ç±»å‹",
            ["æƒ…æ„Ÿåˆ†æ", "å‘½åå®ä½“è¯†åˆ«"]
        )
        
        # å¯¼èˆª
        self.navigation()
        
        # æ ‡æ³¨ç•Œé¢
        if annotation_type == "æƒ…æ„Ÿåˆ†æ":
            self.annotate_sentiment()
        elif annotation_type == "å‘½åå®ä½“è¯†åˆ«":
            self.annotate_ner()
        
        # å¯¼å‡ºåŠŸèƒ½
        st.sidebar.subheader("å¯¼å‡ºæ ‡æ³¨")
        self.export_annotations()
        
        # æ˜¾ç¤ºæ ‡æ³¨ç»Ÿè®¡
        if st.session_state.annotations:
            st.sidebar.subheader("æ ‡æ³¨ç»Ÿè®¡")
            st.sidebar.write(f"å·²æ ‡æ³¨: {len(st.session_state.annotations)} æ¡")
            st.sidebar.write(f"å‰©ä½™: {len(st.session_state.texts) - len(st.session_state.annotations)} æ¡")

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    app = TextAnnotationTool()
    app.run()
```

### å•†ä¸šæ ‡æ³¨å¹³å°

#### ä¼—åŒ…æ ‡æ³¨å¹³å°
- **Amazon Mechanical Turk**ï¼šäºšé©¬é€Šä¼—åŒ…å¹³å°
- **Figure Eight (now Appen)**ï¼šä¸“ä¸šæ•°æ®æ ‡æ³¨æœåŠ¡
- **Labelbox**ï¼šç«¯åˆ°ç«¯æ ‡æ³¨å¹³å°
- **Scale AI**ï¼šAIè®­ç»ƒæ•°æ®å¹³å°

#### ä¼ä¸šçº§æ ‡æ³¨è§£å†³æ–¹æ¡ˆ
- **Supervisely**ï¼šè®¡ç®—æœºè§†è§‰æ ‡æ³¨å¹³å°
- **Hasty.ai**ï¼šAIè¾…åŠ©æ ‡æ³¨å·¥å…·
- **V7 Labs**ï¼šåŒ»å­¦å›¾åƒæ ‡æ³¨ä¸“ç”¨
- **Dataloop**ï¼šæ•°æ®ç®¡ç†å’Œæ ‡æ³¨å¹³å°

## ğŸ“Š æ ‡æ³¨è´¨é‡æ§åˆ¶

### è´¨é‡è¯„ä¼°æŒ‡æ ‡
```python
import numpy as np
from sklearn.metrics import cohen_kappa_score, accuracy_score
import pandas as pd

class AnnotationQualityControl:
    def __init__(self):
        pass
    
    def inter_annotator_agreement(self, annotations_df):
        """è®¡ç®—æ ‡æ³¨è€…é—´ä¸€è‡´æ€§"""
        annotators = annotations_df['annotator'].unique()
        agreements = {}
        
        for i, ann1 in enumerate(annotators):
            for ann2 in annotators[i+1:]:
                # è·å–ä¸¤ä¸ªæ ‡æ³¨è€…çš„å…±åŒæ ‡æ³¨
                ann1_data = annotations_df[annotations_df['annotator'] == ann1]
                ann2_data = annotations_df[annotations_df['annotator'] == ann2]
                
                # åˆå¹¶å…±åŒé¡¹ç›®
                common = pd.merge(ann1_data, ann2_data, on='item_id', 
                                suffixes=('_1', '_2'))
                
                if len(common) > 0:
                    # è®¡ç®—Cohen's Kappa
                    kappa = cohen_kappa_score(common['label_1'], common['label_2'])
                    accuracy = accuracy_score(common['label_1'], common['label_2'])
                    
                    agreements[f"{ann1}_vs_{ann2}"] = {
                        'kappa': kappa,
                        'accuracy': accuracy,
                        'common_items': len(common)
                    }
        
        return agreements
    
    def calculate_annotation_time_stats(self, annotations_df):
        """è®¡ç®—æ ‡æ³¨æ—¶é—´ç»Ÿè®¡"""
        if 'start_time' in annotations_df.columns and 'end_time' in annotations_df.columns:
            annotations_df['duration'] = (
                pd.to_datetime(annotations_df['end_time']) - 
                pd.to_datetime(annotations_df['start_time'])
            ).dt.total_seconds()
            
            stats = {
                'mean_duration': annotations_df['duration'].mean(),
                'median_duration': annotations_df['duration'].median(),
                'std_duration': annotations_df['duration'].std(),
                'min_duration': annotations_df['duration'].min(),
                'max_duration': annotations_df['duration'].max()
            }
            
            # æ£€æµ‹å¼‚å¸¸å¿«é€Ÿæˆ–ç¼“æ…¢çš„æ ‡æ³¨
            Q1 = annotations_df['duration'].quantile(0.25)
            Q3 = annotations_df['duration'].quantile(0.75)
            IQR = Q3 - Q1
            
            outliers = annotations_df[
                (annotations_df['duration'] < Q1 - 1.5 * IQR) |
                (annotations_df['duration'] > Q3 + 1.5 * IQR)
            ]
            
            stats['outlier_count'] = len(outliers)
            stats['outlier_percentage'] = len(outliers) / len(annotations_df) * 100
            
            return stats
        else:
            return {"error": "ç¼ºå°‘æ—¶é—´æˆ³ä¿¡æ¯"}
    
    def detect_annotation_patterns(self, annotations_df):
        """æ£€æµ‹æ ‡æ³¨æ¨¡å¼å¼‚å¸¸"""
        patterns = {}
        
        # æ£€æµ‹æ ‡æ³¨åˆ†å¸ƒ
        label_distribution = annotations_df['label'].value_counts(normalize=True)
        patterns['label_distribution'] = label_distribution.to_dict()
        
        # æ£€æµ‹æ ‡æ³¨è€…åå¥½
        annotator_patterns = annotations_df.groupby('annotator')['label'].value_counts(normalize=True)
        patterns['annotator_preferences'] = annotator_patterns.to_dict()
        
        # æ£€æµ‹æ—¶é—´åå¥½
        if 'timestamp' in annotations_df.columns:
            annotations_df['hour'] = pd.to_datetime(annotations_df['timestamp']).dt.hour
            time_patterns = annotations_df.groupby('annotator')['hour'].apply(
                lambda x: x.value_counts(normalize=True).head(3)
            )
            patterns['time_preferences'] = time_patterns.to_dict()
        
        return patterns

# ä½¿ç”¨ç¤ºä¾‹
annotations_data = pd.DataFrame({
    'item_id': range(100),
    'annotator': np.random.choice(['A', 'B', 'C'], 100),
    'label': np.random.choice(['positive', 'negative', 'neutral'], 100),
    'confidence': np.random.uniform(0.5, 1.0, 100),
    'start_time': pd.date_range('2024-01-01', periods=100, freq='H'),
    'end_time': pd.date_range('2024-01-01 00:30:00', periods=100, freq='H')
})

qc = AnnotationQualityControl()
agreements = qc.inter_annotator_agreement(annotations_data)
time_stats = qc.calculate_annotation_time_stats(annotations_data)
patterns = qc.detect_annotation_patterns(annotations_data)

print("æ ‡æ³¨è€…é—´ä¸€è‡´æ€§:", agreements)
print("æ ‡æ³¨æ—¶é—´ç»Ÿè®¡:", time_stats)
print("æ ‡æ³¨æ¨¡å¼:", patterns)
```

### ä¸»åŠ¨å­¦ä¹ ä¸è‡ªåŠ¨åŒ–æ ‡æ³¨
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score
import numpy as np

class ActiveLearningAnnotation:
    def __init__(self, model=None):
        self.model = model or RandomForestClassifier(n_estimators=100)
        self.vectorizer = TfidfVectorizer(max_features=1000)
        self.labeled_data = []
        self.unlabeled_data = []
    
    def add_labeled_data(self, texts, labels):
        """æ·»åŠ å·²æ ‡æ³¨æ•°æ®"""
        for text, label in zip(texts, labels):
            self.labeled_data.append({'text': text, 'label': label})
    
    def add_unlabeled_data(self, texts):
        """æ·»åŠ æœªæ ‡æ³¨æ•°æ®"""
        for text in texts:
            self.unlabeled_data.append({'text': text})
    
    def train_model(self):
        """è®­ç»ƒå½“å‰æ¨¡å‹"""
        if len(self.labeled_data) < 2:
            return False
        
        texts = [item['text'] for item in self.labeled_data]
        labels = [item['label'] for item in self.labeled_data]
        
        # ç‰¹å¾æå–
        X = self.vectorizer.fit_transform(texts)
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X, labels)
        return True
    
    def uncertainty_sampling(self, n_samples=10):
        """ä¸ç¡®å®šæ€§é‡‡æ ·"""
        if not self.unlabeled_data:
            return []
        
        texts = [item['text'] for item in self.unlabeled_data]
        X = self.vectorizer.transform(texts)
        
        # è·å–é¢„æµ‹æ¦‚ç‡
        probabilities = self.model.predict_proba(X)
        
        # è®¡ç®—ä¸ç¡®å®šæ€§ï¼ˆç†µï¼‰
        uncertainties = []
        for prob in probabilities:
            entropy = -np.sum(prob * np.log(prob + 1e-10))
            uncertainties.append(entropy)
        
        # é€‰æ‹©æœ€ä¸ç¡®å®šçš„æ ·æœ¬
        uncertain_indices = np.argsort(uncertainties)[-n_samples:]
        
        selected_samples = []
        for idx in uncertain_indices:
            selected_samples.append({
                'index': idx,
                'text': self.unlabeled_data[idx]['text'],
                'uncertainty': uncertainties[idx],
                'probabilities': probabilities[idx].tolist()
            })
        
        return selected_samples
    
    def diversity_sampling(self, n_samples=10):
        """å¤šæ ·æ€§é‡‡æ ·"""
        if not self.unlabeled_data:
            return []
        
        texts = [item['text'] for item in self.unlabeled_data]
        X = self.vectorizer.transform(texts).toarray()
        
        # é€‰æ‹©å¤šæ ·æ€§æœ€å¤§çš„æ ·æœ¬
        selected_indices = []
        remaining_indices = list(range(len(texts)))
        
        # éšæœºé€‰æ‹©ç¬¬ä¸€ä¸ªæ ·æœ¬
        first_idx = np.random.choice(remaining_indices)
        selected_indices.append(first_idx)
        remaining_indices.remove(first_idx)
        
        # è¿­ä»£é€‰æ‹©ä¸å·²é€‰æ ·æœ¬å·®å¼‚æœ€å¤§çš„æ ·æœ¬
        for _ in range(min(n_samples - 1, len(remaining_indices))):
            max_min_distance = -1
            best_idx = None
            
            for candidate_idx in remaining_indices:
                min_distance = float('inf')
                
                for selected_idx in selected_indices:
                    distance = np.linalg.norm(X[candidate_idx] - X[selected_idx])
                    min_distance = min(min_distance, distance)
                
                if min_distance > max_min_distance:
                    max_min_distance = min_distance
                    best_idx = candidate_idx
            
            if best_idx is not None:
                selected_indices.append(best_idx)
                remaining_indices.remove(best_idx)
        
        selected_samples = []
        for idx in selected_indices:
            selected_samples.append({
                'index': idx,
                'text': self.unlabeled_data[idx]['text']
            })
        
        return selected_samples
    
    def auto_annotate(self, confidence_threshold=0.9):
        """è‡ªåŠ¨æ ‡æ³¨é«˜ç½®ä¿¡åº¦æ ·æœ¬"""
        if not self.unlabeled_data:
            return []
        
        texts = [item['text'] for item in self.unlabeled_data]
        X = self.vectorizer.transform(texts)
        
        probabilities = self.model.predict_proba(X)
        predictions = self.model.predict(X)
        
        auto_annotated = []
        indices_to_remove = []
        
        for i, (prob, pred) in enumerate(zip(probabilities, predictions)):
            max_confidence = np.max(prob)
            
            if max_confidence >= confidence_threshold:
                auto_annotated.append({
                    'text': texts[i],
                    'label': pred,
                    'confidence': max_confidence
                })
                indices_to_remove.append(i)
        
        # ç§»é™¤è‡ªåŠ¨æ ‡æ³¨çš„æ ·æœ¬
        for idx in sorted(indices_to_remove, reverse=True):
            self.unlabeled_data.pop(idx)
        
        return auto_annotated

# ä½¿ç”¨ç¤ºä¾‹
# åˆå§‹åŒ–ä¸»åŠ¨å­¦ä¹ ç³»ç»Ÿ
al_system = ActiveLearningAnnotation()

# æ·»åŠ åˆå§‹æ ‡æ³¨æ•°æ®
initial_texts = ["è¿™ä¸ªäº§å“å¾ˆå¥½", "è´¨é‡å¤ªå·®äº†", "è¿˜å¯ä»¥å§"]
initial_labels = ["positive", "negative", "neutral"]
al_system.add_labeled_data(initial_texts, initial_labels)

# æ·»åŠ å¾…æ ‡æ³¨æ•°æ®
unlabeled_texts = ["éå¸¸æ»¡æ„", "ä¸æ¨èè´­ä¹°", "æ€§ä»·æ¯”ä¸€èˆ¬", "è¶…å‡ºé¢„æœŸ"]
al_system.add_unlabeled_data(unlabeled_texts)

# è®­ç»ƒåˆå§‹æ¨¡å‹
al_system.train_model()

# è·å–éœ€è¦äººå·¥æ ‡æ³¨çš„æ ·æœ¬
uncertain_samples = al_system.uncertainty_sampling(n_samples=2)
diverse_samples = al_system.diversity_sampling(n_samples=2)

print("ä¸ç¡®å®šæ€§é‡‡æ ·ç»“æœ:", uncertain_samples)
print("å¤šæ ·æ€§é‡‡æ ·ç»“æœ:", diverse_samples)

# è‡ªåŠ¨æ ‡æ³¨é«˜ç½®ä¿¡åº¦æ ·æœ¬
auto_labeled = al_system.auto_annotate(confidence_threshold=0.8)
print("è‡ªåŠ¨æ ‡æ³¨ç»“æœ:", auto_labeled)
```

## ğŸ¯ ç‰¹å®šé¢†åŸŸæ ‡æ³¨

### åŒ»å­¦å›¾åƒæ ‡æ³¨
```python
import cv2
import numpy as np
from sklearn.cluster import KMeans

class MedicalImageAnnotation:
    def __init__(self):
        self.annotations = {}
    
    def segment_lesion(self, image_path, roi_coordinates=None):
        """ç—…ç¶åˆ†å‰²æ ‡æ³¨"""
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        
        if roi_coordinates:
            # æå–æ„Ÿå…´è¶£åŒºåŸŸ
            x1, y1, x2, y2 = roi_coordinates
            roi = image[y1:y2, x1:x2]
        else:
            roi = image
        
        # ä½¿ç”¨K-meansè¿›è¡Œåˆæ­¥åˆ†å‰²
        data = roi.reshape((-1, 1))
        kmeans = KMeans(n_clusters=3, random_state=42)
        labels = kmeans.fit_predict(data)
        
        # é‡å¡‘ä¸ºå›¾åƒå½¢çŠ¶
        segmented = labels.reshape(roi.shape)
        
        return segmented, roi
    
    def annotate_anatomical_structure(self, image_path, structure_type):
        """è§£å‰–ç»“æ„æ ‡æ³¨"""
        structures = {
            'heart': {'color': (255, 0, 0), 'thickness': 2},
            'lung': {'color': (0, 255, 0), 'thickness': 2},
            'liver': {'color': (0, 0, 255), 'thickness': 2},
            'kidney': {'color': (255, 255, 0), 'thickness': 2}
        }
        
        annotation = {
            'image_path': image_path,
            'structure_type': structure_type,
            'properties': structures.get(structure_type, {'color': (255, 255, 255), 'thickness': 1}),
            'timestamp': datetime.now().isoformat()
        }
        
        return annotation
    
    def measure_distance(self, point1, point2, pixel_spacing):
        """æµ‹é‡è·ç¦»ï¼ˆæ¯«ç±³ï¼‰"""
        pixel_distance = np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)
        real_distance = pixel_distance * pixel_spacing
        return real_distance
    
    def calculate_area(self, contour, pixel_spacing):
        """è®¡ç®—é¢ç§¯ï¼ˆå¹³æ–¹æ¯«ç±³ï¼‰"""
        pixel_area = cv2.contourArea(contour)
        real_area = pixel_area * (pixel_spacing ** 2)
        return real_area

# æ³•å¾‹æ–‡æ¡£æ ‡æ³¨
class LegalDocumentAnnotation:
    def __init__(self):
        self.legal_entities = [
            'PERSON', 'ORGANIZATION', 'LOCATION', 'DATE', 'MONEY',
            'LAW', 'CASE', 'COURT', 'JUDGE', 'LAWYER'
        ]
    
    def extract_legal_entities(self, text):
        """æå–æ³•å¾‹å®ä½“"""
        # è¿™é‡Œå¯ä»¥é›†æˆä¸“é—¨çš„æ³•å¾‹NLPæ¨¡å‹
        entities = []
        
        # ç®€å•çš„è§„åˆ™åŸºç¡€å®ä½“è¯†åˆ«ç¤ºä¾‹
        import re
        
        # æ—¥æœŸæ¨¡å¼
        date_pattern = r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥'
        dates = re.finditer(date_pattern, text)
        for match in dates:
            entities.append({
                'text': match.group(),
                'type': 'DATE',
                'start': match.start(),
                'end': match.end()
            })
        
        # é‡‘é¢æ¨¡å¼
        money_pattern = r'\d+(?:,\d{3})*(?:\.\d{2})?å…ƒ'
        money_matches = re.finditer(money_pattern, text)
        for match in money_matches:
            entities.append({
                'text': match.group(),
                'type': 'MONEY',
                'start': match.start(),
                'end': match.end()
            })
        
        return entities
    
    def annotate_clause_type(self, clause_text):
        """æ ‡æ³¨æ¡æ¬¾ç±»å‹"""
        clause_types = {
            'æƒåˆ©ä¹‰åŠ¡': ['æƒåˆ©', 'ä¹‰åŠ¡', 'è´£ä»»', 'æƒé™'],
            'è¿çº¦è´£ä»»': ['è¿çº¦', 'èµ”å¿', 'æŸå¤±', 'è´£ä»»'],
            'äº‰è®®è§£å†³': ['äº‰è®®', 'ä»²è£', 'è¯‰è®¼', 'ç®¡è¾–'],
            'ç”Ÿæ•ˆæ¡ä»¶': ['ç”Ÿæ•ˆ', 'ç»ˆæ­¢', 'æœŸé™', 'æ¡ä»¶']
        }
        
        scores = {}
        for clause_type, keywords in clause_types.items():
            score = sum(1 for keyword in keywords if keyword in clause_text)
            scores[clause_type] = score
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„æ¡æ¬¾ç±»å‹
        best_type = max(scores, key=scores.get)
        return best_type if scores[best_type] > 0 else 'å…¶ä»–'
```

## ğŸ“ˆ æ ‡æ³¨æ•ˆç‡ä¼˜åŒ–

### æ‰¹é‡æ ‡æ³¨ç­–ç•¥
```python
class BatchAnnotationStrategy:
    def __init__(self):
        self.batch_size = 50
        self.strategies = ['random', 'similar', 'diverse', 'uncertain']
    
    def create_batches(self, data, strategy='similar'):
        """åˆ›å»ºæ ‡æ³¨æ‰¹æ¬¡"""
        if strategy == 'random':
            return self._random_batches(data)
        elif strategy == 'similar':
            return self._similar_batches(data)
        elif strategy == 'diverse':
            return self._diverse_batches(data)
        elif strategy == 'uncertain':
            return self._uncertain_batches(data)
    
    def _similar_batches(self, data):
        """åˆ›å»ºç›¸ä¼¼æ ·æœ¬æ‰¹æ¬¡"""
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.cluster import KMeans
        
        # å‡è®¾dataæ˜¯æ–‡æœ¬åˆ—è¡¨
        vectorizer = TfidfVectorizer(max_features=100)
        features = vectorizer.fit_transform(data)
        
        # èšç±»
        n_clusters = len(data) // self.batch_size
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(features)
        
        # æŒ‰èšç±»åˆ†ç»„
        batches = {}
        for i, cluster_id in enumerate(clusters):
            if cluster_id not in batches:
                batches[cluster_id] = []
            batches[cluster_id].append(data[i])
        
        return list(batches.values())
    
    def estimate_annotation_time(self, batch, complexity_factor=1.0):
        """ä¼°è®¡æ ‡æ³¨æ—¶é—´"""
        base_time_per_sample = 30  # ç§’
        estimated_time = len(batch) * base_time_per_sample * complexity_factor
        return estimated_time
    
    def optimize_annotator_assignment(self, batches, annotators):
        """ä¼˜åŒ–æ ‡æ³¨è€…åˆ†é…"""
        assignments = {}
        
        for i, batch in enumerate(batches):
            # ç®€å•çš„è½®è¯¢åˆ†é…
            annotator = annotators[i % len(annotators)]
            if annotator not in assignments:
                assignments[annotator] = []
            assignments[annotator].append({
                'batch_id': i,
                'batch': batch,
                'estimated_time': self.estimate_annotation_time(batch)
            })
        
        return assignments
```

## ğŸ“š æœ€ä½³å®è·µ

### æ ‡æ³¨æŒ‡å—åˆ¶å®š
1. **æ˜ç¡®æ ‡æ³¨æ ‡å‡†**ï¼šè¯¦ç»†å®šä¹‰æ¯ä¸ªæ ‡ç­¾çš„å«ä¹‰å’Œé€‚ç”¨èŒƒå›´
2. **æä¾›ç¤ºä¾‹**ï¼šä¸ºæ¯ç§æƒ…å†µæä¾›æ­£é¢å’Œè´Ÿé¢ç¤ºä¾‹
3. **å¤„ç†è¾¹ç•Œæƒ…å†µ**ï¼šæ˜ç¡®æ¨¡ç³Šæƒ…å†µçš„å¤„ç†æ–¹å¼
4. **å»ºç«‹å®¡æ ¸æµç¨‹**ï¼šè®¾ç½®å¤šçº§å®¡æ ¸å’Œè´¨é‡æ§åˆ¶æœºåˆ¶

### æ ‡æ³¨è€…åŸ¹è®­
1. **ç†è®ºåŸ¹è®­**ï¼šä»‹ç»é¡¹ç›®èƒŒæ™¯å’Œæ ‡æ³¨ç›®æ ‡
2. **å®è·µè®­ç»ƒ**ï¼šé€šè¿‡ç¤ºä¾‹æ•°æ®è¿›è¡Œç»ƒä¹ 
3. **ä¸€è‡´æ€§æµ‹è¯•**ï¼šè¯„ä¼°æ ‡æ³¨è€…é—´çš„ä¸€è‡´æ€§
4. **æŒç»­åé¦ˆ**ï¼šå®šæœŸæ£€æŸ¥å’Œæ”¹è¿›æ ‡æ³¨è´¨é‡

### æŠ€æœ¯å·¥å…·é›†æˆ
1. **ç‰ˆæœ¬æ§åˆ¶**ï¼šä½¿ç”¨Gitç­‰å·¥å…·ç®¡ç†æ ‡æ³¨æ•°æ®ç‰ˆæœ¬
2. **è‡ªåŠ¨åŒ–æ£€æŸ¥**ï¼šå¼€å‘è„šæœ¬è‡ªåŠ¨æ£€æµ‹æ ‡æ³¨é”™è¯¯
3. **æ•°æ®å¤‡ä»½**ï¼šå®šæœŸå¤‡ä»½æ ‡æ³¨æ•°æ®é˜²æ­¢ä¸¢å¤±
4. **è¿›åº¦è·Ÿè¸ª**ï¼šå®æ—¶ç›‘æ§æ ‡æ³¨è¿›åº¦å’Œè´¨é‡æŒ‡æ ‡

## ğŸ”— å¯¼èˆªé“¾æ¥

- [è¿”å›ä¸»é¡µ](../index.html)
- [ä¸Šä¸€æ¨¡å—ï¼šæ•°æ®æå–ä¸åˆ†æ](data-extraction.html)
- [ä¸‹ä¸€æ¨¡å—ï¼šæ•°æ®åœºæ™¯æ£€ç´¢](scene-retrieval.html)
