---
layout: page
title: 数据生成和场景编辑
---

> **模块目标**：聚焦自动驾驶（Autonomous Driving）场景，系统掌握数据生成方法：传统方法生成及基于生成式模型的方法。

# 数据生成概述（自动驾驶）

自动驾驶合成数据通过仿真、程序化、或生成式模型构造道路交通场景与多传感器数据（相机、LiDAR、Radar、IMU、GNSS）。其核心价值：

- 覆盖长尾与危险场景（急刹、鬼探头、雨雾夜、逆光、眩光、强遮挡）
- 降低采集与标注成本，同时保证严格的传感器同步与外参一致性
- 在可控条件下进行可重复实验与A/B评测，支撑算法快速迭代

# 方法总览

## 知识驱动与规则基系统（Rule-Based Approaches）

### 规则/程序生成（Rule-based / Procedural / Agent-based）

做法：人工写规则、文法、程序或代理行为（IF…THEN…、Agent-based 模型）。

优点：可控、可解释、容易加入业务约束/物理规则。

典型场景：仿真器（交通/物流/金融市场）、地形/地图/网络拓扑程序化生成、合成日志。

例如，组合测试用于高效地生成测试用例，通过确保输入参数的关键组合被覆盖来发现系统缺陷。其核心概念是覆盖阵列（Covering Array, CA）。覆盖阵列定义公式 (Covering Array Notation):
$$\text{CA}(N; t, k, v)$$

$N$: 数组中的行数（即生成的测试用例总数）。

$t$: 强度（Strength），表示希望覆盖的参数组合的最大元数（例如， $t=2$ 表示覆盖所有两两组合）。

$k$: 参数数量（Number of factors）。

$v$: 每个参数的符号或值数量（Number of symbols per factor）。

一个 $CA(N; t, k, v)$ 是一个 $N \times k$ 矩阵，它使用来自 $v$ 元字母表 $G$ 的符号，确保在任何 $t \times N$ 子数组中， $G^t$ 中的每个 $t$ 元组都被覆盖至少一次。

### 物理/数值仿真 + 蒙特卡罗（Simulation / Monte Carlo）

做法：写出机理方程或随机过程（SDE、马尔可夫过程），用随机采样推进；或在仿真器里做随机扰动。

优点：与现实机理一致，便于做灵敏度分析与不确定性传播。

典型场景：可靠性工程、风险评估、交通微观仿真、排队论系统、期权与利率路径生成。



### 合成渲染/程序化内容（CGI / Synthetic Rendering）

做法：用 3D 引擎或渲染管线 + 程序化资产/材质/光照/噪声来出图/出视频/出点云，标签自动生成。

优点：可控性强、覆盖极端角落；与仿真/规则法常组合。

## 经典统计建模与概率推断（Statistical Modelling）

### 参数化统计建模（Parametric）

核心：假设分布族，估计参数后按分布采样；

优点：高效、抽样简单、易解释；

典型场景：金融风控（联合违约/收益）、可靠性寿命分布、计数/到达过程。

### 非参数与重采样（Nonparametric / Resampling）

核心：尽量少假设，直接用样本近似密度或不确定性，Bootstrap、Permutation、KDE（核密度估计）、直方图采样、平滑重采样。

优点：少假设，贴近数据分布；在样本不大时可稳健估计不确定性。

典型场景：置信区间/假设检验、经验分布抽样、生成“与历史相似”的样本。

### 概率图模型 / 隐变量模型（PGM / Latent-variable）

核心：用图结构刻画条件独立，定义生成过程并据此采样。

做法：贝叶斯网络、马尔可夫网络、HMM/HSMM、LDA、混合成员模型；

优点：结构化可解释；能编码先验与因果/条件独立关系。

典型场景：序列/主题/分群的生成，缺失值补全，情景条件化生成。

<!-- ### 最大熵与约束驱动（Maximum Entropy / Constraint-based）

做法：给定一组矩/边缘/规则，求满足这些约束且熵最大的分布；或解约束满足问题（CSP）后再随机化。

优点：当你只确信少量统计量或硬约束时，非常自然。

典型场景：网络/图生成（给定度分布）、合成分类账/日志、罕见事件约束采样。 -->

## Generative model 

### 辅助技术：潜在空间插值（Latent Space Interpolation）

潜在空间插值是一种数据生成技术，它本身不是独立的模型，而是 VAE 等深度生成模型用于数据增强和探索潜在空间的关键技术 。

数学公式最常用的线性插值形式：
$$\mathbf{z}_{\text{interp}} = \alpha \mathbf{z}_A + (1 - \alpha) \mathbf{z}_B$$

$\mathbf{z}_{\text{interp}}$: 插值后的潜在向量。

$\mathbf{z}_A, \mathbf{z}_B$: 两个来自潜在空间的起始向量。

$\alpha$: 插值系数，其中 $\alpha \in (0,1) $。

新数据（平滑变体）的生成过程该技术利用深度模型（尤其是 VAE）潜在空间的连续性来构造新数据 。

选择锚点：在已训练模型的潜在空间中，选择两个代表不同特征的潜在向量 $\mathbf{z}_A$ 和 $\mathbf{z}_B$。

构造路径：根据插值公式，在 $\mathbf{z}_A$ 和 $\mathbf{z}_B$ 之间生成一系列中间向量 $\mathbf{z}_{\text{interp}}$。

解码：将每个 $\mathbf{z}_{\text{interp}}$ 输入到生成器网络（解码器）中。

输出：生成器输出一个连续的、从 $\mathbf{x}_A$ 渐变到 $\mathbf{x}_B$ 的新合成数据序列。

具体例子：驾驶轨迹的细微变异生成用于生成 ADS 验证所需的边缘案例。通过插值，可以平滑地生成从“安全跟车”轨迹到“轻微追尾风险”轨迹之间的一系列细微变异数据，用于评估 ADS 对不确定性的鲁棒性。

### Autoregressive

$$ p(\mathbf{x}) = \prod_{i=1}^{D} p\!\left(x_i \mid x_{<i}\right) $$
<!-- 按顺序建模（Transformer/PixelRNN）。优点：似然明确；缺点：推断慢。

$ p(x)=∏_{i=1}^D​p(x_i​∣x_{<i}​) $

### VAE
显式潜变量 + 变分下界；优点：有似然下界、可控；缺点：模糊/后验坍缩需技巧。

### GAN

对抗学习，生成质量高；缺点：训练不稳、无显式似然。

### Normalizing Flows

可逆映射、精确似然、采样快；对结构设计有要求。

### Diffusion/Score-based

鲁棒、质量高、覆盖好；采样步数多（可加速）。

### Energy-based / Flow-matching / Schrödinger Bridge / OT

以能量或连续时间运输为核心，兼顾物理与概率解释。 -->
<!-- $ \frac{d x(t)}{dt} = v_{\theta}\!\big(x(t), t\big), \qquad x(0)\!\sim p_0,\;\; x(1)\!\sim p_{\text{data}} $ -->

# 导航链接

- [返回主页](../index.html)
- [上一模块：数据与场景可视化](data-visualization.html)
- [下一模块：数据应用](data-application.html)
