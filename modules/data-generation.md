---
layout: page
title: æ•°æ®ç”Ÿæˆå’Œåœºæ™¯ç¼–è¾‘
---

# æ•°æ®ç”Ÿæˆå’Œåœºæ™¯ç¼–è¾‘

> ğŸ¬ **æ¨¡å—ç›®æ ‡**ï¼šæŒæ¡æ•°æ®ç”ŸæˆæŠ€æœ¯å’Œåœºæ™¯ç¼–è¾‘æ–¹æ³•ï¼Œåˆ›å»ºåˆæˆæ•°æ®é›†å’Œè™šæ‹Ÿåœºæ™¯

## ğŸŒŸ æ•°æ®ç”Ÿæˆæ¦‚è¿°

æ•°æ®ç”Ÿæˆæ˜¯åˆ›å»ºäººå·¥åˆæˆæ•°æ®çš„è¿‡ç¨‹ï¼Œç”¨äºå¢å¼ºè®­ç»ƒæ•°æ®é›†ã€ä¿æŠ¤éšç§ã€æµ‹è¯•ç®—æ³•æ€§èƒ½ç­‰ç›®çš„ã€‚ç»“åˆå…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹å’Œåœºæ™¯ç¼–è¾‘æŠ€æœ¯ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºé«˜è´¨é‡ã€å¤šæ ·åŒ–çš„æ•°æ®é›†æ¥æ”¯æŒå„ç§æœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚

## ğŸ¤– ç”Ÿæˆæ¨¡å‹æŠ€æœ¯

### ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN)
```python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, TensorDataset

class Generator(nn.Module):
    def __init__(self, noise_dim=100, output_dim=784):  # 28x28 = 784 for MNIST
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(noise_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, output_dim),
            nn.Tanh()
        )
    
    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self, input_dim=784):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 1024),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.model(x)

class GANTrainer:
    def __init__(self, noise_dim=100, lr=0.0002):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.noise_dim = noise_dim
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.generator = Generator(noise_dim).to(self.device)
        self.discriminator = Discriminator().to(self.device)
        
        # ä¼˜åŒ–å™¨
        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=lr, betas=(0.5, 0.999))
        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(0.5, 0.999))
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.BCELoss()
        
        # è®­ç»ƒå†å²
        self.g_losses = []
        self.d_losses = []
    
    def train(self, dataloader, epochs=100):
        """è®­ç»ƒGAN"""
        for epoch in range(epochs):
            for i, (real_data, _) in enumerate(dataloader):
                batch_size = real_data.size(0)
                real_data = real_data.view(batch_size, -1).to(self.device)
                
                # è®­ç»ƒåˆ¤åˆ«å™¨
                self.d_optimizer.zero_grad()
                
                # çœŸå®æ•°æ®
                real_labels = torch.ones(batch_size, 1).to(self.device)
                real_output = self.discriminator(real_data)
                d_loss_real = self.criterion(real_output, real_labels)
                
                # ç”Ÿæˆæ•°æ®
                noise = torch.randn(batch_size, self.noise_dim).to(self.device)
                fake_data = self.generator(noise)
                fake_labels = torch.zeros(batch_size, 1).to(self.device)
                fake_output = self.discriminator(fake_data.detach())
                d_loss_fake = self.criterion(fake_output, fake_labels)
                
                d_loss = d_loss_real + d_loss_fake
                d_loss.backward()
                self.d_optimizer.step()
                
                # è®­ç»ƒç”Ÿæˆå™¨
                self.g_optimizer.zero_grad()
                
                fake_output = self.discriminator(fake_data)
                g_loss = self.criterion(fake_output, real_labels)
                g_loss.backward()
                self.g_optimizer.step()
                
                # è®°å½•æŸå¤±
                if i % 100 == 0:
                    self.g_losses.append(g_loss.item())
                    self.d_losses.append(d_loss.item())
                    print(f'Epoch [{epoch}/{epochs}], Step [{i}/{len(dataloader)}], '
                          f'D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')
    
    def generate_samples(self, num_samples=64):
        """ç”Ÿæˆæ ·æœ¬"""
        self.generator.eval()
        with torch.no_grad():
            noise = torch.randn(num_samples, self.noise_dim).to(self.device)
            generated_data = self.generator(noise)
            generated_data = generated_data.cpu().numpy()
        return generated_data.reshape(num_samples, 28, 28)  # å‡è®¾æ˜¯28x28å›¾åƒ
    
    def plot_training_progress(self):
        """ç»˜åˆ¶è®­ç»ƒè¿›åº¦"""
        plt.figure(figsize=(12, 4))
        
        plt.subplot(1, 2, 1)
        plt.plot(self.g_losses, label='Generator Loss')
        plt.plot(self.d_losses, label='Discriminator Loss')
        plt.xlabel('Iteration')
        plt.ylabel('Loss')
        plt.title('Training Loss')
        plt.legend()
        
        plt.subplot(1, 2, 2)
        samples = self.generate_samples(16)
        fig, axes = plt.subplots(4, 4, figsize=(8, 8))
        for i, ax in enumerate(axes.flat):
            ax.imshow(samples[i], cmap='gray')
            ax.axis('off')
        plt.suptitle('Generated Samples')
        plt.tight_layout()
        plt.show()
```

### å˜åˆ†è‡ªç¼–ç å™¨ (VAE)
```python
class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(VAE, self).__init__()
        
        # ç¼–ç å™¨
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc21 = nn.Linear(hidden_dim, latent_dim)  # å‡å€¼
        self.fc22 = nn.Linear(hidden_dim, latent_dim)  # æ–¹å·®
        
        # è§£ç å™¨
        self.fc3 = nn.Linear(latent_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, input_dim)
        
    def encode(self, x):
        h1 = torch.relu(self.fc1(x))
        return self.fc21(h1), self.fc22(h1)
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h3 = torch.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h3))
    
    def forward(self, x):
        mu, logvar = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

class VAETrainer:
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20, lr=1e-3):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = VAE(input_dim, hidden_dim, latent_dim).to(self.device)
        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)
        
    def loss_function(self, recon_x, x, mu, logvar):
        """VAEæŸå¤±å‡½æ•°"""
        BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')
        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
        return BCE + KLD
    
    def train(self, dataloader, epochs=10):
        """è®­ç»ƒVAE"""
        self.model.train()
        train_loss = 0
        
        for epoch in range(epochs):
            for batch_idx, (data, _) in enumerate(dataloader):
                data = data.to(self.device)
                self.optimizer.zero_grad()
                
                recon_batch, mu, logvar = self.model(data)
                loss = self.loss_function(recon_batch, data, mu, logvar)
                
                loss.backward()
                train_loss += loss.item()
                self.optimizer.step()
                
                if batch_idx % 100 == 0:
                    print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(dataloader.dataset)} '
                          f'({100. * batch_idx / len(dataloader):.0f}%)]\tLoss: {loss.item() / len(data):.6f}')
    
    def generate_samples(self, num_samples=64):
        """ç”Ÿæˆæ ·æœ¬"""
        self.model.eval()
        with torch.no_grad():
            z = torch.randn(num_samples, 20).to(self.device)
            samples = self.model.decode(z)
            return samples.cpu().numpy().reshape(num_samples, 28, 28)
    
    def interpolate_latent_space(self, point1, point2, num_steps=10):
        """åœ¨æ½œåœ¨ç©ºé—´ä¸­æ’å€¼"""
        self.model.eval()
        with torch.no_grad():
            # åˆ›å»ºæ’å€¼è·¯å¾„
            alpha = torch.linspace(0, 1, num_steps).unsqueeze(1).to(self.device)
            interpolated = alpha * point1 + (1 - alpha) * point2
            
            # è§£ç æ’å€¼ç‚¹
            samples = self.model.decode(interpolated)
            return samples.cpu().numpy().reshape(num_steps, 28, 28)
```

### Diffusion Models
```python
import math

class DiffusionModel(nn.Module):
    def __init__(self, img_size=32, in_channels=3, model_channels=128, num_res_blocks=2):
        super(DiffusionModel, self).__init__()
        
        self.img_size = img_size
        self.in_channels = in_channels
        
        # æ—¶é—´åµŒå…¥
        self.time_embed = nn.Sequential(
            nn.Linear(model_channels, model_channels * 4),
            nn.SiLU(),
            nn.Linear(model_channels * 4, model_channels * 4),
        )
        
        # U-Netæ¶æ„
        self.input_blocks = nn.ModuleList([
            nn.Conv2d(in_channels, model_channels, 3, padding=1)
        ])
        
        # ä¸‹é‡‡æ ·
        for level in range(3):
            for _ in range(num_res_blocks):
                self.input_blocks.append(
                    ResBlock(model_channels, model_channels, model_channels * 4)
                )
            if level < 2:
                self.input_blocks.append(nn.Conv2d(model_channels, model_channels, 3, stride=2, padding=1))
        
        # ä¸­é—´å±‚
        self.middle_block = ResBlock(model_channels, model_channels, model_channels * 4)
        
        # ä¸Šé‡‡æ ·
        self.output_blocks = nn.ModuleList()
        for level in range(3):
            for _ in range(num_res_blocks + 1):
                self.output_blocks.append(
                    ResBlock(model_channels * 2, model_channels, model_channels * 4)
                )
            if level < 2:
                self.output_blocks.append(nn.ConvTranspose2d(model_channels, model_channels, 4, stride=2, padding=1))
        
        # è¾“å‡ºå±‚
        self.out = nn.Sequential(
            nn.GroupNorm(8, model_channels),
            nn.SiLU(),
            nn.Conv2d(model_channels, in_channels, 3, padding=1),
        )
    
    def forward(self, x, timesteps):
        # æ—¶é—´åµŒå…¥
        t_emb = self.time_embedding(timesteps)
        
        # U-Netå‰å‘ä¼ æ’­
        h = x
        hs = []
        
        # ä¸‹é‡‡æ ·
        for module in self.input_blocks:
            if isinstance(module, ResBlock):
                h = module(h, t_emb)
            else:
                h = module(h)
            hs.append(h)
        
        # ä¸­é—´å±‚
        h = self.middle_block(h, t_emb)
        
        # ä¸Šé‡‡æ ·
        for module in self.output_blocks:
            if isinstance(module, ResBlock):
                h = torch.cat([h, hs.pop()], dim=1)
                h = module(h, t_emb)
            else:
                h = module(h)
        
        return self.out(h)
    
    def time_embedding(self, timesteps):
        """æ—¶é—´æ­¥åµŒå…¥"""
        half_dim = 64
        emb = math.log(10000) / (half_dim - 1)
        emb = torch.exp(torch.arange(half_dim) * -emb).to(timesteps.device)
        emb = timesteps[:, None] * emb[None, :]
        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)
        return self.time_embed(emb)

class ResBlock(nn.Module):
    def __init__(self, in_channels, out_channels, time_emb_dim):
        super(ResBlock, self).__init__()
        
        self.time_mlp = nn.Linear(time_emb_dim, out_channels)
        
        self.block1 = nn.Sequential(
            nn.GroupNorm(8, in_channels),
            nn.SiLU(),
            nn.Conv2d(in_channels, out_channels, 3, padding=1)
        )
        
        self.block2 = nn.Sequential(
            nn.GroupNorm(8, out_channels),
            nn.SiLU(),
            nn.Conv2d(out_channels, out_channels, 3, padding=1)
        )
        
        if in_channels != out_channels:
            self.residual_conv = nn.Conv2d(in_channels, out_channels, 1)
        else:
            self.residual_conv = nn.Identity()
    
    def forward(self, x, time_emb):
        h = self.block1(x)
        
        # æ·»åŠ æ—¶é—´åµŒå…¥
        time_emb = self.time_mlp(time_emb)
        h = h + time_emb[:, :, None, None]
        
        h = self.block2(h)
        
        return h + self.residual_conv(x)

class DDPMSampler:
    def __init__(self, model, num_timesteps=1000, beta_start=0.0001, beta_end=0.02):
        self.model = model
        self.num_timesteps = num_timesteps
        
        # å™ªå£°è°ƒåº¦
        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
        
    def add_noise(self, x_0, noise, timesteps):
        """å‘å›¾åƒæ·»åŠ å™ªå£°"""
        sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod[timesteps])
        sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod[timesteps])
        
        return (sqrt_alphas_cumprod[:, None, None, None] * x_0 + 
                sqrt_one_minus_alphas_cumprod[:, None, None, None] * noise)
    
    def sample(self, shape, device):
        """ä»å™ªå£°ä¸­é‡‡æ ·å›¾åƒ"""
        x = torch.randn(shape).to(device)
        
        for t in reversed(range(self.num_timesteps)):
            t_tensor = torch.full((shape[0],), t, dtype=torch.long, device=device)
            
            # é¢„æµ‹å™ªå£°
            with torch.no_grad():
                pred_noise = self.model(x, t_tensor)
            
            # å»å™ªæ­¥éª¤
            alpha = self.alphas[t]
            alpha_cumprod = self.alphas_cumprod[t]
            beta = self.betas[t]
            
            if t > 0:
                noise = torch.randn_like(x)
            else:
                noise = torch.zeros_like(x)
            
            x = (1 / torch.sqrt(alpha)) * (x - ((1 - alpha) / torch.sqrt(1 - alpha_cumprod)) * pred_noise)
            x = x + torch.sqrt(beta) * noise
        
        return x
```

## ğŸ—ï¸ åˆæˆæ•°æ®ç”Ÿæˆ

### è¡¨æ ¼æ•°æ®ç”Ÿæˆ
```python
import pandas as pd
from sklearn.mixture import GaussianMixture
from scipy import stats
import random

class TabularDataGenerator:
    def __init__(self):
        self.column_distributions = {}
        self.correlation_matrix = None
        
    def fit(self, data):
        """å­¦ä¹ æ•°æ®åˆ†å¸ƒ"""
        self.data = data
        
        # å­¦ä¹ æ¯åˆ—çš„åˆ†å¸ƒ
        for column in data.columns:
            if data[column].dtype in ['int64', 'float64']:
                # æ•°å€¼åˆ—ï¼šä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹
                gmm = GaussianMixture(n_components=3)
                gmm.fit(data[column].values.reshape(-1, 1))
                self.column_distributions[column] = {
                    'type': 'numeric',
                    'model': gmm,
                    'min': data[column].min(),
                    'max': data[column].max()
                }
            else:
                # åˆ†ç±»åˆ—ï¼šä½¿ç”¨é¢‘ç‡åˆ†å¸ƒ
                value_counts = data[column].value_counts(normalize=True)
                self.column_distributions[column] = {
                    'type': 'categorical',
                    'probabilities': value_counts.to_dict()
                }
        
        # è®¡ç®—æ•°å€¼åˆ—ä¹‹é—´çš„ç›¸å…³æ€§
        numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns
        if len(numeric_columns) > 1:
            self.correlation_matrix = data[numeric_columns].corr()
    
    def generate_samples(self, num_samples=1000, maintain_correlations=True):
        """ç”Ÿæˆåˆæˆæ ·æœ¬"""
        synthetic_data = {}
        
        if maintain_correlations and self.correlation_matrix is not None:
            # ç”Ÿæˆä¿æŒç›¸å…³æ€§çš„æ•°å€¼æ•°æ®
            numeric_columns = list(self.correlation_matrix.columns)
            multivariate_normal = stats.multivariate_normal(
                mean=np.zeros(len(numeric_columns)),
                cov=self.correlation_matrix.values
            )
            
            # ç”Ÿæˆç›¸å…³çš„æ­£æ€åˆ†å¸ƒæ ·æœ¬
            correlated_samples = multivariate_normal.rvs(num_samples)
            
            # è½¬æ¢ä¸ºåŸå§‹åˆ†å¸ƒ
            for i, column in enumerate(numeric_columns):
                # ä½¿ç”¨é€†å˜æ¢é‡‡æ ·
                uniform_samples = stats.norm.cdf(correlated_samples[:, i])
                
                # ä»å­¦ä¹ çš„åˆ†å¸ƒä¸­é‡‡æ ·
                if self.column_distributions[column]['type'] == 'numeric':
                    model = self.column_distributions[column]['model']
                    # è¿‘ä¼¼é€†å˜æ¢
                    samples = []
                    for _ in range(num_samples):
                        sample = model.sample()[0][0]
                        samples.append(sample)
                    synthetic_data[column] = samples
        else:
            # ç‹¬ç«‹ç”Ÿæˆæ¯åˆ—
            for column, dist_info in self.column_distributions.items():
                if dist_info['type'] == 'numeric':
                    model = dist_info['model']
                    samples = model.sample(num_samples)[0].flatten()
                    # ç¡®ä¿åœ¨åŸå§‹èŒƒå›´å†…
                    samples = np.clip(samples, dist_info['min'], dist_info['max'])
                    synthetic_data[column] = samples
                
                elif dist_info['type'] == 'categorical':
                    categories = list(dist_info['probabilities'].keys())
                    probabilities = list(dist_info['probabilities'].values())
                    samples = np.random.choice(categories, size=num_samples, p=probabilities)
                    synthetic_data[column] = samples
        
        return pd.DataFrame(synthetic_data)
    
    def generate_conditional_samples(self, conditions, num_samples=100):
        """ç”Ÿæˆæ¡ä»¶æ ·æœ¬"""
        synthetic_data = {}
        
        # é¦–å…ˆè®¾ç½®æ¡ä»¶åˆ—
        for column, value in conditions.items():
            if isinstance(value, list):
                synthetic_data[column] = np.random.choice(value, num_samples)
            else:
                synthetic_data[column] = [value] * num_samples
        
        # ç”Ÿæˆå…¶ä»–åˆ—
        for column, dist_info in self.column_distributions.items():
            if column not in conditions:
                if dist_info['type'] == 'numeric':
                    model = dist_info['model']
                    samples = model.sample(num_samples)[0].flatten()
                    synthetic_data[column] = samples
                elif dist_info['type'] == 'categorical':
                    categories = list(dist_info['probabilities'].keys())
                    probabilities = list(dist_info['probabilities'].values())
                    samples = np.random.choice(categories, size=num_samples, p=probabilities)
                    synthetic_data[column] = samples
        
        return pd.DataFrame(synthetic_data)
    
    def evaluate_quality(self, original_data, synthetic_data):
        """è¯„ä¼°åˆæˆæ•°æ®è´¨é‡"""
        quality_metrics = {}
        
        # ç»Ÿè®¡ç›¸ä¼¼æ€§
        for column in original_data.columns:
            if column in synthetic_data.columns:
                if original_data[column].dtype in ['int64', 'float64']:
                    # KSæ£€éªŒ
                    ks_stat, ks_p = stats.ks_2samp(
                        original_data[column].dropna(),
                        synthetic_data[column].dropna()
                    )
                    quality_metrics[f'{column}_ks_stat'] = ks_stat
                    quality_metrics[f'{column}_ks_p'] = ks_p
                    
                    # å‡å€¼å’Œæ ‡å‡†å·®æ¯”è¾ƒ
                    orig_mean = original_data[column].mean()
                    synth_mean = synthetic_data[column].mean()
                    quality_metrics[f'{column}_mean_diff'] = abs(orig_mean - synth_mean) / orig_mean
                    
                    orig_std = original_data[column].std()
                    synth_std = synthetic_data[column].std()
                    quality_metrics[f'{column}_std_diff'] = abs(orig_std - synth_std) / orig_std
                
                else:
                    # åˆ†ç±»åˆ—ï¼šåˆ†å¸ƒç›¸ä¼¼æ€§
                    orig_dist = original_data[column].value_counts(normalize=True)
                    synth_dist = synthetic_data[column].value_counts(normalize=True)
                    
                    # è®¡ç®—JSæ•£åº¦
                    all_categories = set(orig_dist.index) | set(synth_dist.index)
                    orig_probs = [orig_dist.get(cat, 0) for cat in all_categories]
                    synth_probs = [synth_dist.get(cat, 0) for cat in all_categories]
                    
                    js_div = self.jensen_shannon_divergence(orig_probs, synth_probs)
                    quality_metrics[f'{column}_js_divergence'] = js_div
        
        # ç›¸å…³æ€§ä¿æŒ
        if self.correlation_matrix is not None:
            orig_corr = original_data.corr()
            synth_corr = synthetic_data.corr()
            corr_diff = np.abs(orig_corr - synth_corr).mean().mean()
            quality_metrics['correlation_preservation'] = 1 - corr_diff
        
        return quality_metrics
    
    def jensen_shannon_divergence(self, p, q):
        """è®¡ç®—JSæ•£åº¦"""
        p = np.array(p) + 1e-10  # é¿å…log(0)
        q = np.array(q) + 1e-10
        m = 0.5 * (p + q)
        
        return 0.5 * stats.entropy(p, m) + 0.5 * stats.entropy(q, m)

# ä½¿ç”¨ç¤ºä¾‹
# generator = TabularDataGenerator()
# generator.fit(original_data)
# synthetic_data = generator.generate_samples(1000)
# quality = generator.evaluate_quality(original_data, synthetic_data)
```

### æ—¶é—´åºåˆ—æ•°æ®ç”Ÿæˆ
```python
class TimeSeriesGenerator:
    def __init__(self):
        self.trend_model = None
        self.seasonal_model = None
        self.noise_model = None
        
    def decompose_series(self, time_series, period=12):
        """åˆ†è§£æ—¶é—´åºåˆ—"""
        from statsmodels.tsa.seasonal import seasonal_decompose
        
        decomposition = seasonal_decompose(time_series, model='additive', period=period)
        
        self.trend = decomposition.trend.dropna()
        self.seasonal = decomposition.seasonal
        self.residual = decomposition.resid.dropna()
        
        return decomposition
    
    def fit_trend_model(self, trend_data):
        """æ‹Ÿåˆè¶‹åŠ¿æ¨¡å‹"""
        from sklearn.linear_model import LinearRegression
        from sklearn.preprocessing import PolynomialFeatures
        
        X = np.arange(len(trend_data)).reshape(-1, 1)
        
        # å°è¯•ä¸åŒé˜¶æ•°çš„å¤šé¡¹å¼
        best_score = -np.inf
        best_model = None
        
        for degree in [1, 2, 3]:
            poly_features = PolynomialFeatures(degree=degree)
            X_poly = poly_features.fit_transform(X)
            
            model = LinearRegression()
            model.fit(X_poly, trend_data)
            score = model.score(X_poly, trend_data)
            
            if score > best_score:
                best_score = score
                best_model = (poly_features, model)
        
        self.trend_model = best_model
        return best_model
    
    def generate_trend(self, length):
        """ç”Ÿæˆè¶‹åŠ¿"""
        if self.trend_model is None:
            return np.zeros(length)
        
        poly_features, model = self.trend_model
        X = np.arange(length).reshape(-1, 1)
        X_poly = poly_features.transform(X)
        
        return model.predict(X_poly)
    
    def generate_seasonal_pattern(self, length, period=12):
        """ç”Ÿæˆå­£èŠ‚æ€§æ¨¡å¼"""
        if not hasattr(self, 'seasonal'):
            # ç”Ÿæˆç®€å•çš„æ­£å¼¦æ³¢å­£èŠ‚æ€§
            t = np.arange(length)
            seasonal = np.sin(2 * np.pi * t / period)
            return seasonal
        
        # é‡å¤å·²å­¦ä¹ çš„å­£èŠ‚æ€§æ¨¡å¼
        seasonal_pattern = self.seasonal[:period].values
        full_pattern = np.tile(seasonal_pattern, length // period + 1)
        return full_pattern[:length]
    
    def generate_noise(self, length, noise_type='gaussian'):
        """ç”Ÿæˆå™ªå£°"""
        if noise_type == 'gaussian':
            if hasattr(self, 'residual'):
                noise_std = self.residual.std()
            else:
                noise_std = 0.1
            return np.random.normal(0, noise_std, length)
        
        elif noise_type == 'autoregressive':
            # AR(1) å™ªå£°
            if hasattr(self, 'residual'):
                from statsmodels.tsa.ar_model import AutoReg
                try:
                    ar_model = AutoReg(self.residual.dropna(), lags=1).fit()
                    noise = ar_model.forecast(length)
                    return noise
                except:
                    return np.random.normal(0, 0.1, length)
            else:
                return np.random.normal(0, 0.1, length)
    
    def generate_synthetic_series(self, length, period=12, noise_type='gaussian'):
        """ç”Ÿæˆåˆæˆæ—¶é—´åºåˆ—"""
        # ç”Ÿæˆå„ä¸ªç»„ä»¶
        trend = self.generate_trend(length)
        seasonal = self.generate_seasonal_pattern(length, period)
        noise = self.generate_noise(length, noise_type)
        
        # ç»„åˆæ—¶é—´åºåˆ—
        synthetic_series = trend + seasonal + noise
        
        return synthetic_series
    
    def generate_multiple_series(self, num_series, length, correlation=0.5):
        """ç”Ÿæˆå¤šä¸ªç›¸å…³çš„æ—¶é—´åºåˆ—"""
        # ç”ŸæˆåŸºç¡€ç³»åˆ—
        base_series = self.generate_synthetic_series(length)
        
        series_list = [base_series]
        
        for i in range(num_series - 1):
            # ç”Ÿæˆç›¸å…³ç³»åˆ—
            independent_series = self.generate_synthetic_series(length)
            
            # åˆ›å»ºç›¸å…³æ€§
            correlated_series = (correlation * base_series + 
                               np.sqrt(1 - correlation**2) * independent_series)
            
            series_list.append(correlated_series)
        
        return np.array(series_list).T

# ARIMAæ—¶é—´åºåˆ—ç”Ÿæˆ
class ARIMAGenerator:
    def __init__(self):
        self.model = None
        
    def fit(self, time_series, order=(1, 1, 1)):
        """æ‹ŸåˆARIMAæ¨¡å‹"""
        from statsmodels.tsa.arima.model import ARIMA
        
        self.model = ARIMA(time_series, order=order)
        self.fitted_model = self.model.fit()
        
        return self.fitted_model
    
    def generate_samples(self, num_samples, num_steps=100):
        """ç”ŸæˆARIMAæ ·æœ¬"""
        if self.fitted_model is None:
            raise ValueError("æ¨¡å‹æœªæ‹Ÿåˆ")
        
        samples = []
        for _ in range(num_samples):
            # ç”Ÿæˆé¢„æµ‹
            forecast = self.fitted_model.forecast(steps=num_steps)
            samples.append(forecast)
        
        return np.array(samples)
    
    def simulate_scenarios(self, base_series, num_scenarios=10, horizon=24):
        """æ¨¡æ‹Ÿæœªæ¥åœºæ™¯"""
        scenarios = []
        
        for _ in range(num_scenarios):
            # é‡æ–°æ‹Ÿåˆæ¨¡å‹ï¼ˆæ·»åŠ ä¸€äº›éšæœºæ€§ï¼‰
            noisy_series = base_series + np.random.normal(0, 0.01, len(base_series))
            
            try:
                model = ARIMA(noisy_series, order=(1, 1, 1)).fit()
                forecast = model.forecast(steps=horizon)
                scenarios.append(forecast)
            except:
                # å¦‚æœæ‹Ÿåˆå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å¤–æ¨
                trend = np.polyfit(range(len(base_series)), base_series, 1)
                forecast = np.polyval(trend, range(len(base_series), len(base_series) + horizon))
                scenarios.append(forecast)
        
        return np.array(scenarios)
```

## ğŸ¨ åœºæ™¯ç¼–è¾‘æŠ€æœ¯

### å›¾åƒåœºæ™¯ç¼–è¾‘
```python
import cv2
from PIL import Image, ImageDraw, ImageFont
import numpy as np

class ImageSceneEditor:
    def __init__(self):
        self.layers = []
        self.current_layer = 0
        
    def load_background(self, image_path):
        """åŠ è½½èƒŒæ™¯å›¾åƒ"""
        self.background = cv2.imread(image_path)
        self.height, self.width = self.background.shape[:2]
        self.layers = [self.background.copy()]
        
    def add_object(self, object_image_path, position, scale=1.0, rotation=0):
        """æ·»åŠ ç‰©ä½“åˆ°åœºæ™¯"""
        obj_img = cv2.imread(object_image_path, cv2.IMREAD_UNCHANGED)
        
        # ç¼©æ”¾
        if scale != 1.0:
            new_width = int(obj_img.shape[1] * scale)
            new_height = int(obj_img.shape[0] * scale)
            obj_img = cv2.resize(obj_img, (new_width, new_height))
        
        # æ—‹è½¬
        if rotation != 0:
            center = (obj_img.shape[1] // 2, obj_img.shape[0] // 2)
            rotation_matrix = cv2.getRotationMatrix2D(center, rotation, 1.0)
            obj_img = cv2.warpAffine(obj_img, rotation_matrix, 
                                   (obj_img.shape[1], obj_img.shape[0]))
        
        # æ·»åŠ åˆ°åœºæ™¯
        self.add_layer_at_position(obj_img, position)
    
    def add_layer_at_position(self, layer_img, position):
        """åœ¨æŒ‡å®šä½ç½®æ·»åŠ å›¾å±‚"""
        x, y = position
        h, w = layer_img.shape[:2]
        
        # åˆ›å»ºæ–°å›¾å±‚
        new_layer = self.layers[-1].copy()
        
        # ç¡®ä¿ä½ç½®åœ¨ç”»å¸ƒèŒƒå›´å†…
        if x + w > self.width:
            w = self.width - x
            layer_img = layer_img[:, :w]
        if y + h > self.height:
            h = self.height - y
            layer_img = layer_img[:h, :]
        if x < 0:
            layer_img = layer_img[:, -x:]
            w = layer_img.shape[1]
            x = 0
        if y < 0:
            layer_img = layer_img[-y:, :]
            h = layer_img.shape[0]
            y = 0
        
        # å¤„ç†é€æ˜åº¦
        if layer_img.shape[2] == 4:  # RGBA
            alpha = layer_img[:, :, 3] / 255.0
            for c in range(3):
                new_layer[y:y+h, x:x+w, c] = (
                    alpha * layer_img[:, :, c] + 
                    (1 - alpha) * new_layer[y:y+h, x:x+w, c]
                )
        else:  # RGB
            new_layer[y:y+h, x:x+w] = layer_img
        
        self.layers.append(new_layer)
    
    def change_lighting(self, brightness=0, contrast=1.0):
        """æ”¹å˜å…‰ç…§"""
        current_layer = self.layers[-1].copy()
        
        # è°ƒæ•´äº®åº¦å’Œå¯¹æ¯”åº¦
        adjusted = cv2.convertScaleAbs(current_layer, alpha=contrast, beta=brightness)
        
        self.layers.append(adjusted)
    
    def add_weather_effect(self, weather_type='rain', intensity=0.5):
        """æ·»åŠ å¤©æ°”æ•ˆæœ"""
        current_layer = self.layers[-1].copy()
        
        if weather_type == 'rain':
            # ç”Ÿæˆé›¨æ»´
            rain_layer = np.zeros_like(current_layer)
            
            num_drops = int(1000 * intensity)
            for _ in range(num_drops):
                x = np.random.randint(0, self.width)
                y = np.random.randint(0, self.height)
                length = np.random.randint(10, 30)
                
                cv2.line(rain_layer, (x, y), (x + 2, y + length), (200, 200, 200), 1)
            
            # æ··åˆé›¨æ»´æ•ˆæœ
            result = cv2.addWeighted(current_layer, 1 - intensity * 0.3, 
                                   rain_layer, intensity * 0.3, 0)
        
        elif weather_type == 'fog':
            # æ·»åŠ é›¾æ•ˆ
            fog_layer = np.full_like(current_layer, 180)  # ç°è‰²é›¾
            result = cv2.addWeighted(current_layer, 1 - intensity * 0.6, 
                                   fog_layer, intensity * 0.6, 0)
        
        elif weather_type == 'snow':
            # ç”Ÿæˆé›ªèŠ±
            snow_layer = np.zeros_like(current_layer)
            
            num_flakes = int(500 * intensity)
            for _ in range(num_flakes):
                x = np.random.randint(0, self.width)
                y = np.random.randint(0, self.height)
                radius = np.random.randint(1, 4)
                
                cv2.circle(snow_layer, (x, y), radius, (255, 255, 255), -1)
            
            result = cv2.addWeighted(current_layer, 1, snow_layer, intensity, 0)
        
        self.layers.append(result)
    
    def segment_and_replace_background(self, new_background_path):
        """åˆ†å‰²å¹¶æ›¿æ¢èƒŒæ™¯"""
        # è¿™é‡Œåº”è¯¥ä½¿ç”¨æ›´é«˜çº§çš„åˆ†å‰²æ¨¡å‹ï¼Œå¦‚DeepLabæˆ–Mask R-CNN
        # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨GrabCut
        
        current_layer = self.layers[-1].copy()
        mask = np.zeros(current_layer.shape[:2], np.uint8)
        
        # åˆå§‹åŒ–çŸ©å½¢ï¼ˆå‡è®¾ä¸»ä½“åœ¨ä¸­å¤®ï¼‰
        rect = (self.width//4, self.height//4, self.width//2, self.height//2)
        
        # GrabCutåˆ†å‰²
        bgdModel = np.zeros((1, 65), np.float64)
        fgdModel = np.zeros((1, 65), np.float64)
        
        cv2.grabCut(current_layer, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)
        
        # åˆ›å»ºå‰æ™¯æ©ç 
        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
        
        # åŠ è½½æ–°èƒŒæ™¯
        new_bg = cv2.imread(new_background_path)
        new_bg = cv2.resize(new_bg, (self.width, self.height))
        
        # åˆæˆç»“æœ
        result = new_bg.copy()
        result = result * (1 - mask2[:, :, np.newaxis]) + current_layer * mask2[:, :, np.newaxis]
        
        self.layers.append(result.astype(np.uint8))
    
    def add_text_annotation(self, text, position, font_size=30, color=(255, 255, 255)):
        """æ·»åŠ æ–‡æœ¬æ³¨é‡Š"""
        current_layer = self.layers[-1].copy()
        
        # è½¬æ¢ä¸ºPILå›¾åƒä»¥æ”¯æŒæ›´å¥½çš„æ–‡æœ¬æ¸²æŸ“
        pil_image = Image.fromarray(cv2.cvtColor(current_layer, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        # å°è¯•åŠ è½½å­—ä½“
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            font = ImageFont.load_default()
        
        # ç»˜åˆ¶æ–‡æœ¬
        draw.text(position, text, font=font, fill=color)
        
        # è½¬æ¢å›OpenCVæ ¼å¼
        result = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        self.layers.append(result)
    
    def generate_variations(self, num_variations=5):
        """ç”Ÿæˆåœºæ™¯å˜åŒ–"""
        base_layer = self.layers[0].copy()
        variations = []
        
        for i in range(num_variations):
            # éšæœºè°ƒæ•´
            brightness = np.random.randint(-30, 31)
            contrast = np.random.uniform(0.8, 1.2)
            
            # åº”ç”¨è°ƒæ•´
            variation = cv2.convertScaleAbs(base_layer, alpha=contrast, beta=brightness)
            
            # éšæœºå¤©æ°”æ•ˆæœ
            weather_effects = ['rain', 'fog', 'snow', None]
            weather = np.random.choice(weather_effects)
            
            if weather:
                intensity = np.random.uniform(0.2, 0.8)
                # åº”ç”¨å¤©æ°”æ•ˆæœï¼ˆç®€åŒ–ç‰ˆï¼‰
                if weather == 'rain':
                    # æ·»åŠ ä¸€äº›å™ªå£°æ¨¡æ‹Ÿé›¨æ°´
                    noise = np.random.normal(0, 10, variation.shape).astype(np.int16)
                    variation = np.clip(variation.astype(np.int16) + noise, 0, 255).astype(np.uint8)
            
            variations.append(variation)
        
        return variations
    
    def export_scene(self, output_path):
        """å¯¼å‡ºå½“å‰åœºæ™¯"""
        current_scene = self.layers[-1]
        cv2.imwrite(output_path, current_scene)
        
    def get_current_scene(self):
        """è·å–å½“å‰åœºæ™¯"""
        return self.layers[-1]
```

### 3Dåœºæ™¯ç¼–è¾‘
```python
import open3d as o3d
import numpy as np

class Scene3DEditor:
    def __init__(self):
        self.scene_objects = []
        self.materials = {}
        self.lighting = []
        
    def load_3d_model(self, file_path, object_id=None):
        """åŠ è½½3Dæ¨¡å‹"""
        if file_path.endswith('.ply'):
            mesh = o3d.io.read_triangle_mesh(file_path)
        elif file_path.endswith('.obj'):
            mesh = o3d.io.read_triangle_mesh(file_path)
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
        
        if object_id is None:
            object_id = f"object_{len(self.scene_objects)}"
        
        scene_object = {
            'id': object_id,
            'mesh': mesh,
            'position': np.array([0, 0, 0]),
            'rotation': np.array([0, 0, 0]),
            'scale': np.array([1, 1, 1]),
            'material': 'default'
        }
        
        self.scene_objects.append(scene_object)
        return object_id
    
    def create_primitive(self, primitive_type, size=1.0, object_id=None):
        """åˆ›å»ºåŸºæœ¬å‡ ä½•ä½“"""
        if primitive_type == 'cube':
            mesh = o3d.geometry.TriangleMesh.create_box(width=size, height=size, depth=size)
        elif primitive_type == 'sphere':
            mesh = o3d.geometry.TriangleMesh.create_sphere(radius=size)
        elif primitive_type == 'cylinder':
            mesh = o3d.geometry.TriangleMesh.create_cylinder(radius=size, height=size*2)
        elif primitive_type == 'plane':
            mesh = o3d.geometry.TriangleMesh.create_box(width=size*2, height=0.1, depth=size*2)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å‡ ä½•ä½“ç±»å‹: {primitive_type}")
        
        if object_id is None:
            object_id = f"{primitive_type}_{len(self.scene_objects)}"
        
        scene_object = {
            'id': object_id,
            'mesh': mesh,
            'position': np.array([0, 0, 0]),
            'rotation': np.array([0, 0, 0]),
            'scale': np.array([1, 1, 1]),
            'material': 'default'
        }
        
        self.scene_objects.append(scene_object)
        return object_id
    
    def transform_object(self, object_id, position=None, rotation=None, scale=None):
        """å˜æ¢ç‰©ä½“"""
        obj = self.get_object_by_id(object_id)
        if obj is None:
            return
        
        if position is not None:
            obj['position'] = np.array(position)
        if rotation is not None:
            obj['rotation'] = np.array(rotation)
        if scale is not None:
            obj['scale'] = np.array(scale)
        
        self.apply_transforms(obj)
    
    def apply_transforms(self, scene_object):
        """åº”ç”¨å˜æ¢"""
        mesh = scene_object['mesh']
        
        # é‡ç½®å˜æ¢
        mesh.translate(-mesh.get_center())
        
        # ç¼©æ”¾
        scale = scene_object['scale']
        mesh.scale(scale[0], center=mesh.get_center())
        
        # æ—‹è½¬
        rotation = scene_object['rotation']
        if np.any(rotation != 0):
            R = mesh.get_rotation_matrix_from_xyz(rotation)
            mesh.rotate(R, center=mesh.get_center())
        
        # å¹³ç§»
        position = scene_object['position']
        mesh.translate(position)
    
    def get_object_by_id(self, object_id):
        """æ ¹æ®IDè·å–ç‰©ä½“"""
        for obj in self.scene_objects:
            if obj['id'] == object_id:
                return obj
        return None
    
    def set_material(self, object_id, color=None, texture_path=None):
        """è®¾ç½®æè´¨"""
        obj = self.get_object_by_id(object_id)
        if obj is None:
            return
        
        if color is not None:
            obj['mesh'].paint_uniform_color(color)
        
        if texture_path is not None:
            # åŠ è½½çº¹ç†ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            texture = o3d.io.read_image(texture_path)
            # Open3Dçš„çº¹ç†æ”¯æŒæœ‰é™ï¼Œè¿™é‡Œåªæ˜¯ç¤ºä¾‹
            obj['texture'] = texture
    
    def add_lighting(self, light_type='point', position=[0, 5, 0], intensity=1.0, color=[1, 1, 1]):
        """æ·»åŠ å…‰æº"""
        light = {
            'type': light_type,
            'position': np.array(position),
            'intensity': intensity,
            'color': np.array(color)
        }
        self.lighting.append(light)
    
    def duplicate_object(self, object_id, new_id=None, offset=[1, 0, 0]):
        """å¤åˆ¶ç‰©ä½“"""
        original_obj = self.get_object_by_id(object_id)
        if original_obj is None:
            return None
        
        if new_id is None:
            new_id = f"{object_id}_copy_{len(self.scene_objects)}"
        
        # æ·±åº¦å¤åˆ¶ç½‘æ ¼
        new_mesh = original_obj['mesh'].copy()
        
        new_object = {
            'id': new_id,
            'mesh': new_mesh,
            'position': original_obj['position'] + np.array(offset),
            'rotation': original_obj['rotation'].copy(),
            'scale': original_obj['scale'].copy(),
            'material': original_obj['material']
        }
        
        self.scene_objects.append(new_object)
        self.apply_transforms(new_object)
        
        return new_id
    
    def create_array(self, object_id, grid_size=(3, 3), spacing=2.0):
        """åˆ›å»ºç‰©ä½“é˜µåˆ—"""
        created_objects = []
        
        for i in range(grid_size[0]):
            for j in range(grid_size[1]):
                if i == 0 and j == 0:
                    continue  # è·³è¿‡åŸå§‹ç‰©ä½“
                
                offset = [i * spacing, 0, j * spacing]
                new_id = self.duplicate_object(object_id, 
                                             f"{object_id}_array_{i}_{j}", 
                                             offset)
                if new_id:
                    created_objects.append(new_id)
        
        return created_objects
    
    def generate_random_scene(self, num_objects=10, scene_bounds=[-10, 10]):
        """ç”Ÿæˆéšæœºåœºæ™¯"""
        primitives = ['cube', 'sphere', 'cylinder']
        colors = [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1]]
        
        for i in range(num_objects):
            # éšæœºé€‰æ‹©å‡ ä½•ä½“ç±»å‹
            primitive = np.random.choice(primitives)
            size = np.random.uniform(0.5, 2.0)
            
            # åˆ›å»ºç‰©ä½“
            obj_id = self.create_primitive(primitive, size)
            
            # éšæœºä½ç½®
            position = np.random.uniform(scene_bounds[0], scene_bounds[1], 3)
            position[1] = max(0, position[1])  # ç¡®ä¿åœ¨åœ°é¢ä»¥ä¸Š
            
            # éšæœºæ—‹è½¬
            rotation = np.random.uniform(0, 2*np.pi, 3)
            
            # éšæœºç¼©æ”¾
            scale = np.random.uniform(0.5, 1.5, 3)
            
            # åº”ç”¨å˜æ¢
            self.transform_object(obj_id, position, rotation, scale)
            
            # éšæœºé¢œè‰²
            color = np.random.choice(colors)
            self.set_material(obj_id, color)
    
    def export_scene(self, output_path):
        """å¯¼å‡ºåœºæ™¯"""
        combined_mesh = o3d.geometry.TriangleMesh()
        
        for obj in self.scene_objects:
            combined_mesh += obj['mesh']
        
        o3d.io.write_triangle_mesh(output_path, combined_mesh)
    
    def visualize_scene(self):
        """å¯è§†åŒ–åœºæ™¯"""
        geometries = []
        
        for obj in self.scene_objects:
            geometries.append(obj['mesh'])
        
        # æ·»åŠ åæ ‡ç³»
        coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=2)
        geometries.append(coordinate_frame)
        
        o3d.visualization.draw_geometries(geometries)
    
    def render_scene(self, camera_position=[0, 5, 10], resolution=(800, 600)):
        """æ¸²æŸ“åœºæ™¯"""
        vis = o3d.visualization.Visualizer()
        vis.create_window(width=resolution[0], height=resolution[1])
        
        for obj in self.scene_objects:
            vis.add_geometry(obj['mesh'])
        
        # è®¾ç½®ç›¸æœº
        ctr = vis.get_view_control()
        ctr.set_front([0, -0.5, -1])
        ctr.set_lookat([0, 0, 0])
        ctr.set_up([0, 1, 0])
        
        # æ¸²æŸ“
        vis.run()
        vis.capture_screen_image("rendered_scene.png")
        vis.destroy_window()
```

## ğŸ”— å¯¼èˆªé“¾æ¥

- [è¿”å›ä¸»é¡µ](../index.html)
- [ä¸Šä¸€æ¨¡å—ï¼šæ•°æ®ä¸åœºæ™¯å¯è§†åŒ–](data-visualization.html)
- [ä¸‹ä¸€æ¨¡å—ï¼šæ•°æ®åº”ç”¨](data-application.html)
